{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myHW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Dcw0Quw701TQXCDVM1ENKhyr7qyCDMky",
      "authorship_tag": "ABX9TyPYwhDe5E4QuK+P5IkRXM8G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huangzhanhua02/ML_study/blob/main/myHW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v-41VvLyz_VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMj55YDKG6ch",
        "outputId": "a63e09e8-c9d7-4bad-c716-28ae1da0f8a8"
      },
      "source": [
        "tr_path = 'covid.train.csv'  # path to training data\n",
        "tt_path = 'covid.test.csv'   # path to testing data\n",
        "\n",
        "!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
        "!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n",
            "To: /content/covid.train.csv\n",
            "100% 2.00M/2.00M [00:00<00:00, 121MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n",
            "To: /content/covid.test.csv\n",
            "100% 651k/651k [00:00<00:00, 94.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_DmG217_z_J",
        "outputId": "408f1f7e-3f06-4546-fe1b-cff3137ca921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 这一模块需要引入的库：\n",
        "import csv\n",
        "import numpy \n",
        "import tensor\n",
        "from tensor.utils.data import Dataset, DataLoader\n",
        " \n",
        "class Covid19dataset(Dataset):\n",
        "    def __init__(self, path, mode='train'):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        " \n",
        "        # 读取数据\n",
        "        with open(path) as file:\n",
        "            data_csv = list(csv.reader(file))   # 将csv文件中获取的数据转换为列表类型\n",
        "            data = np.array(data_csv[1:])[:, 1:].astype(float)  # 获取文件中的【数值数据】\n",
        " \n",
        "        if mode == 'test':  # 由于训练集、验证集与测试集的数据有所不同（最后一列数据），在此分情况运行\n",
        "            data = data[:, 0:93]    # 测试集中，由于最后一行是得预测的数据，故只有93列\n",
        "            self.data = torch.FloatTensor(data)     # 将numpy类型数据转换为tensor类型\n",
        "        else:\n",
        "            target = data[:, -1]    # 训练集和验证集中用于对比结果的“目标”\n",
        "            data = data[:, 0:93]\n",
        "            train_index = []\n",
        "            dev_index = []\n",
        "            for i in range(data.shape[0]):     # 这个循环用于将covid.train.csv文件中的数据分为训练集和验证集\n",
        "                if i % 10 != 0:                # 取序号为整十数的样本作为验证集\n",
        "                    train_index.append(i)\n",
        "                else:\n",
        "                    dev_index.append(i)\n",
        "            if mode == 'train':     # 训练集的数据\n",
        "                self.target = torch.FloatTensor(target[train_index])\n",
        "                self.data = torch.FloatTensor(data[train_index, 0:93])\n",
        "            else:       # 测试集的数据\n",
        "                self.target = torch.FloatTensor(target[dev_index])\n",
        "                self.data = torch.FloatTensor(data[dev_index, 0:93])\n",
        " \n",
        "        # 此处是对数据进行标准化处理，可以将不同量纲的不同特征，变为同一个数量级，使得损失函数更加平滑\n",
        "        # 标准化的优点：①提升模型的精度   ②提升收敛速度\n",
        "        # 采用均值标准化： （第i维数据 - 第i维数据的平均值）/（第i维数据的标准差）\n",
        "        self.data[:, 40:] = (self.data[:, 40:] - self.data[:, 40:].mean(dim=0)) / self.data[:, 40:].std(dim=0)\n",
        " \n",
        "        self.dim = self.data.shape[1]   # 获取数据的列数\n",
        " \n",
        "    def __getitem__(self, item):        # 【注】这是Dataset必须重写的类函数，意在按索引返回数据\n",
        "        if self.mode == 'train' or self.mode == 'dev':  # 训练集和验证集包含特征和目标数据\n",
        "            return self.data[item], self.target[item]\n",
        "        else:\n",
        "            return self.data[item]      # 测试集仅含有特征数据\n",
        " \n",
        "    def __len__(self):                  # 【注】返回数据的行数\n",
        "        return len(self.data)\n",
        " \n",
        " \n",
        "def prep_dataloader(path, mode, batch_size, n_jobs=0):\n",
        "    dataset = Covid19dataset(path, mode)    # 定义一个Dataset类\n",
        "    dataloader = DataLoader(dataset, batch_size,\n",
        "                            shuffle=(mode == 'train'),  # 【是否打乱数据后再读取】\n",
        "                            drop_last=False,            # 【False表示不丢弃不能被batch_size整除的部分】\n",
        "                            num_workers=n_jobs,         # 【采用多少个进程读取数据】\n",
        "                            pin_memory=False)           # 【是否将数据载入CUDA的内存当中】\n",
        "    print(mode, 'data done!')\n",
        "    return dataloader"
      ]
    }
  ]
}